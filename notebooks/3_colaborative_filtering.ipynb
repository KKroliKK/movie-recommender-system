{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from constants import U1BASE_PATH, U1TEST_PATH\n",
    "from benchmark.data_tramsformation import convert_raw_to_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = convert_raw_to_matrix(U1BASE_PATH)\n",
    "test_ratings = convert_raw_to_matrix(U1TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.01523187, 3.28051825, 4.59433714, 3.69621832, 1.88188565,\n",
       "       2.45600504, 1.22541041, 0.64369547, 3.15491882, 3.46615595])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(10) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def fit(self, ratings):\n",
    "        pass\n",
    "\n",
    "    def predict(self, user_id):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomModel(Model):\n",
    "    def __init__(self, max_score = 5) -> None:\n",
    "        self.max_score = max_score\n",
    "    \n",
    "    def fit(self, ratings):\n",
    "        self.shape = ratings.shape[1]\n",
    "\n",
    "    def predict(self, user_id):\n",
    "        prediction = np.random.random(self.shape) * self.max_score\n",
    "\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "class AvgModel(Model):\n",
    "    def get_avg_film_ratings(self, film_id, ratings):\n",
    "        all_ratings = ratings[:, film_id][ratings[:, film_id] != 0]\n",
    "        if len(all_ratings) == 0:\n",
    "            avg_rating = 0\n",
    "        else:\n",
    "            avg_rating = np.average(all_ratings)\n",
    "\n",
    "        return avg_rating\n",
    "    \n",
    "\n",
    "    def fit(self, ratings):\n",
    "        self.avg = [self.get_avg_film_ratings(film_id, ratings) for film_id in range(ratings.shape[1])]\n",
    "        self.avg = np.array(self.avg)\n",
    "\n",
    "    def predict(self, user_id):\n",
    "        return self.avg\n",
    "\n",
    "\n",
    "class ColaborativeModel(Model):\n",
    "    cos_sim = lambda a, b: dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "    def __init__(self, num_users: int = 30) -> None:\n",
    "        self.num_users = num_users\n",
    "\n",
    "    def fit(self, ratings):\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def predict(self, user_id):\n",
    "        user_ratings = self.ratings[user_id]\n",
    "        similarities = np.array([ColaborativeModel.cos_sim(user_ratings, rating) for rating in self.ratings])\n",
    "        closest_users = list(reversed(np.argsort(similarities)))\n",
    "        closest_users = closest_users[1:self.num_users + 1]\n",
    "        \n",
    "        closest_similarities = similarities[closest_users]\n",
    "        sum_closest_similarities = sum(closest_similarities)\n",
    "\n",
    "        closest_ratingss = self.ratings[closest_users]\n",
    "\n",
    "        prediction = np.sum((closest_ratingss * closest_similarities[:, None]), axis=0) / sum_closest_similarities\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rmse(true, prediction):\n",
    "    true_non_null = true != 0\n",
    "\n",
    "    user_non_null = true[true_non_null]\n",
    "    fitted_prediction = prediction[true_non_null]\n",
    "\n",
    "    rmse = mean_squared_error(user_non_null, fitted_prediction, squared=False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00387523, 1.66690773, 3.11551852, ..., 3.92394483, 2.68972337,\n",
       "       2.24981659])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model = RandomModel()\n",
    "random_model.fit(train_ratings)\n",
    "random_model.predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.89295039, 3.18095238, 3.        , ..., 2.        , 3.        ,\n",
       "       3.        ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_model = AvgModel()\n",
    "avg_model.fit(train_ratings)\n",
    "avg_model.predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.352399447092248"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colab_model = ColaborativeModel(num_users=30)\n",
    "colab_model.fit(train_ratings)\n",
    "\n",
    "pred = colab_model.predict(0)\n",
    "\n",
    "count_rmse(test_ratings[0], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rmse_on_dataset(model, data):\n",
    "    sum_rmse = 0\n",
    "    num_predictions = 0\n",
    "\n",
    "    for id, sample in enumerate(data):\n",
    "        if sum(sample) == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model.predict(id)\n",
    "        rmse = count_rmse(sample, pred)\n",
    "\n",
    "        sum_rmse += rmse\n",
    "        num_predictions += 1\n",
    "\n",
    "    rmse = sum_rmse / num_predictions\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5203890678021796"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_rmse_on_dataset(colab_model, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.121163882524208"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_rmse_on_dataset(random_model, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0091275841214649"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_rmse_on_dataset(avg_model, test_ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
