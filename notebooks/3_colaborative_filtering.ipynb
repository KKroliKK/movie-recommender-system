{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from constants import U1BASE_PATH, U1TEST_PATH\n",
    "from benchmark.data_tramsformation import convert_raw_to_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = convert_raw_to_matrix(U1BASE_PATH)\n",
    "test_ratings = convert_raw_to_matrix(U1TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeModel:\n",
    "    cos_sim = lambda a, b: dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "    def __init__(self, num_users: int = 30) -> None:\n",
    "        self.num_users = num_users\n",
    "\n",
    "    def fit(self, ratings):\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def predict(self, user_ratings):\n",
    "        similarities = np.array([ColaborativeModel.cos_sim(user_ratings, rating) for rating in self.ratings])\n",
    "        closest_users = list(reversed(np.argsort(similarities)))\n",
    "        closest_users = closest_users[:self.num_users]\n",
    "        \n",
    "        closest_similarities = similarities[closest_users]\n",
    "        sum_closest_similarities = sum(closest_similarities)\n",
    "\n",
    "        closest_ratingss = train_ratings[closest_users]\n",
    "\n",
    "        prediction = np.sum((closest_ratingss * closest_similarities[:, None]), axis=0) / sum_closest_similarities\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rmse(true, prediction):\n",
    "    true_non_null = true != 0\n",
    "\n",
    "    user_non_null = true[true_non_null]\n",
    "    fitted_prediction = prediction[true_non_null]\n",
    "\n",
    "    rmse = mean_squared_error(user_non_null, fitted_prediction, squared=False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2517708752064904"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colab_model = ColaborativeModel(num_users=30)\n",
    "colab_model.fit(train_ratings)\n",
    "\n",
    "pred = colab_model.predict(test_ratings[0])\n",
    "\n",
    "count_rmse(test_ratings[0], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rmse_on_test(model, test):\n",
    "    for sample in test:\n",
    "        pred = model.predict(sample)\n",
    "        count_rmse(sample, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
